Model Features, Parameters, and Hyperparameters:
X: QuestionId (categorical), PreprocessedExplanation (text), is_correct (binary)
Y: CombinedTarget (categorical)

1. train_test_split(test_size=0.25, stratify=y, random_state=42)

2. Text preprocessing with TF-IDF and ToktokTokenizer on PreprocessedExplanation
def tok(text):
    tt = ToktokTokenizer()
    return tt.tokenize(text)

tfidf = TfidfVectorizer(
    ngram_range=(1, 3),
    max_features=50000,
    sublinear_tf=True,
    tokenizer=tok
)

3. Encode categorical QuestionId with LabelEncoder
4. CSR matrix on encoded QuestionId and binary is_correct
5. Combine preprocessed features into final X_train and X_test
6. Handle class imbalance with RandomOverSampler
7. LGBMClassifier(
    boosting_type="gbdt",
    objective="multiclass",
    num_class=len(np.unique(y_res)),
    class_weight="balanced",
    n_estimators=500,
    learning_rate=0.05,
    max_depth=-1,
    random_state=42,
    n_jobs=-1
)

Combined Target Report:
                 precision    recall  f1-score   support

       Correct       0.83      0.87      0.85      3757
       Neither       0.68      0.57      0.62      2952
      addition       0.77      0.90      0.83       333
    definition       0.77      0.75      0.76       152
      fraction       0.62      0.79      0.70       310
    incomplete       0.74      0.78      0.76       364
multiplication       0.68      0.76      0.72       112
     operation       0.62      0.66      0.64       126
      positive       0.75      0.77      0.76       142
     procedure       0.72      0.80      0.75       325
   subtraction       0.71      0.83      0.76       155
      variable       0.69      0.80      0.74       277
   wholenumber       0.66      0.76      0.71       169

      accuracy                           0.75      9174
     macro avg       0.71      0.77      0.74      9174
  weighted avg       0.75      0.75      0.75      9174