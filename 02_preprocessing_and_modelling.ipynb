{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d6784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import contractions \n",
    "import unicodedata\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f364dc",
   "metadata": {},
   "source": [
    "### Preprocessing Strategy \n",
    "Ultimate goal: predict (1) whether there is a misconception and (2) if there is a misconception, what kind? \n",
    "\n",
    "Preprocessing steps:\n",
    "\n",
    "- Clean up `StudentExplanation` like we did in *01_data_wrangling_eda.ipynb*\n",
    "- Clean up `Misconception` like we did in *01_data_wrangling_eda.ipynb*\n",
    "- Use answer key dictionary with question_id and the correct answer, then use this to make a new feature, `is_correct` (I'm assuming a teacher would have an answer key to check whether the MC answer is correct, and we don't need ML for this part)\n",
    "- Collapse `Category` into Correct, Misconception, and Neither. We don't need the True/False label because we don't need ML to tell us if the MC answer is correct. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014da0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "directory = \"map-charting-student-math-misunderstandings\"\n",
    "train = pd.read_csv(f\"{directory}/train.csv\")\n",
    "# test = pd.read_csv(f\"{directory}/test.csv\") # this csv only has 3 rows and 2 of the 15 questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3c4b44",
   "metadata": {},
   "source": [
    "#### Preprocessing StudentExplanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5764d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    # All lower case\n",
    "    lower_text = text.lower() \n",
    "\n",
    "    # No accented characters\n",
    "    no_accents = unicodedata.normalize('NFKD', lower_text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "    # Expand contractions\n",
    "    expanded = contractions.fix(no_accents)\n",
    "\n",
    "    # Remove repeated words\n",
    "    no_repeats = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', expanded, flags=re.IGNORECASE)\n",
    "\n",
    "    # Remove digits and special characters\n",
    "    no_special_char = re.sub(r'[^a-zA-Z\\s]', '', no_repeats)\n",
    "\n",
    "\n",
    "    # Remove stop words\n",
    "    words = no_special_char.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "train['PreprocessedExplanation'] = train['StudentExplanation'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b2a2ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'incomplete', 'wnb', 'swapdividend', 'mult', 'flipchange',\n",
       "       'irrelevant', 'wrongfraction', 'additive', 'notvariable',\n",
       "       'addingterms', 'inverseoperation', 'inversion', 'duplication',\n",
       "       'wrongoperation', 'wholenumberslarger', 'longerisbigger',\n",
       "       'ignoreszeroes', 'shorterisbigger', 'addingacross',\n",
       "       'denominatoronlychange', 'incorrectequivalentfractionaddition',\n",
       "       'division', 'subtraction', 'unknowable', 'definition', 'interior',\n",
       "       'positive', 'tacking', 'wrongterm', 'firstterm', 'baserate',\n",
       "       'multiplyingby4', 'certainty', 'scale'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize labels & remove special characters\n",
    "train.Misconception = train.Misconception.str.lower() # all lower case\n",
    "train.Misconception = train.Misconception.str.replace('-','') # remove hyphens\n",
    "train.Misconception = train.Misconception.str.replace('_','') # remove underscores\n",
    "train.Misconception = train.Misconception.str.replace(' ','') # remove spaces\n",
    "train.Misconception.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "954e359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA values in Misconception\n",
    "train['Misconception'] = train['Misconception'].fillna('none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2def601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logically combine similar misconception categories \n",
    "wholenumber_miscs = ['wholenumberbias', 'wholenumberslarger', 'longerisbigger', 'shorterisbigger','wnb']\n",
    "fraction_miscs = ['wrongfraction','denominatoronlychange','incorrectequivalentfractionaddition','swapdividend']\n",
    "operation_miscs = ['wrongoperation','inverseoperation','inversion','division']\n",
    "multiplication_miscs = ['multiplyingby4','mult']\n",
    "addition_miscs = ['additive','addingterms','addingacross']\n",
    "variable_miscs = ['notvariable','wrongterm','firstterm','tacking']\n",
    "definition_miscs = ['definition','baserate','scale','certainty','interior','unknowable']\n",
    "procedure_miscs = ['duplication','irrelevant','flipchange','ignoreszeroes']\n",
    "\n",
    "\n",
    "# Replace \n",
    "train['Misconception'] = train['Misconception'].replace(wholenumber_miscs, 'wholenumber')\n",
    "train['Misconception'] = train['Misconception'].replace(fraction_miscs, 'fraction')\n",
    "train['Misconception'] = train['Misconception'].replace(operation_miscs, 'operation')\n",
    "train['Misconception'] = train['Misconception'].replace(multiplication_miscs, 'multiplication')\n",
    "train['Misconception'] = train['Misconception'].replace(addition_miscs, 'addition')\n",
    "train['Misconception'] = train['Misconception'].replace(variable_miscs, 'variable')\n",
    "train['Misconception'] = train['Misconception'].replace(definition_miscs, 'definition')\n",
    "train['Misconception'] = train['Misconception'].replace(procedure_miscs, 'procedure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac7e7cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Misconception to MisconceptionType for clarity\n",
    "train = train.rename(columns={'Misconception':'MisconceptionType'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b89372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use answer_key to make is_correct\n",
    "answer_key = pd.read_csv(f\"{directory}/answer_key.csv\")\n",
    "\n",
    "# Merge answer key into train \n",
    "train = train.merge(answer_key.rename(columns={\"MC_Answer\": \"Correct_Answer\"}),\n",
    "                    on=\"QuestionId\", how=\"left\")\n",
    "\n",
    "# Create is_correct column\n",
    "train[\"is_correct\"] = (train[\"MC_Answer\"] == train[\"Correct_Answer\"]).astype(int)\n",
    "\n",
    "# Remember, an error makes it necessary to manually set QuestionId 31778 to correct if the student answered 9. \n",
    "train.loc[(train['QuestionId'] == 31778) & (train['MC_Answer']=='\\( 9 \\)'), 'is_correct'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a63fa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>MC_Answer</th>\n",
       "      <th>StudentExplanation</th>\n",
       "      <th>Category</th>\n",
       "      <th>MisconceptionType</th>\n",
       "      <th>PreprocessedExplanation</th>\n",
       "      <th>Correct_Answer</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>NewCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>0ne third is equal to tree nineth</td>\n",
       "      <td>True_Correct</td>\n",
       "      <td>none</td>\n",
       "      <td>ne third equal tree nineth</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 / 3 because 6 over 9 is 2 thirds and 1 third...</td>\n",
       "      <td>True_Correct</td>\n",
       "      <td>none</td>\n",
       "      <td>thirds third shaded</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 3rd is half of 3 6th, so it is simplee to un...</td>\n",
       "      <td>True_Neither</td>\n",
       "      <td>none</td>\n",
       "      <td>rd half th simplee understand</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 goes into everything and 3 goes into nine</td>\n",
       "      <td>True_Neither</td>\n",
       "      <td>none</td>\n",
       "      <td>goes everything goes nine</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>31772</td>\n",
       "      <td>What fraction of the shape is not shaded? Give...</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1 out of every 3 isn't coloured</td>\n",
       "      <td>True_Correct</td>\n",
       "      <td>none</td>\n",
       "      <td>every coloured</td>\n",
       "      <td>\\( \\frac{1}{3} \\)</td>\n",
       "      <td>1</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  QuestionId                                       QuestionText  \\\n",
       "0       0       31772  What fraction of the shape is not shaded? Give...   \n",
       "1       1       31772  What fraction of the shape is not shaded? Give...   \n",
       "2       2       31772  What fraction of the shape is not shaded? Give...   \n",
       "3       3       31772  What fraction of the shape is not shaded? Give...   \n",
       "4       4       31772  What fraction of the shape is not shaded? Give...   \n",
       "\n",
       "           MC_Answer                                 StudentExplanation  \\\n",
       "0  \\( \\frac{1}{3} \\)                  0ne third is equal to tree nineth   \n",
       "1  \\( \\frac{1}{3} \\)  1 / 3 because 6 over 9 is 2 thirds and 1 third...   \n",
       "2  \\( \\frac{1}{3} \\)  1 3rd is half of 3 6th, so it is simplee to un...   \n",
       "3  \\( \\frac{1}{3} \\)        1 goes into everything and 3 goes into nine   \n",
       "4  \\( \\frac{1}{3} \\)                    1 out of every 3 isn't coloured   \n",
       "\n",
       "       Category MisconceptionType        PreprocessedExplanation  \\\n",
       "0  True_Correct              none     ne third equal tree nineth   \n",
       "1  True_Correct              none            thirds third shaded   \n",
       "2  True_Neither              none  rd half th simplee understand   \n",
       "3  True_Neither              none      goes everything goes nine   \n",
       "4  True_Correct              none                 every coloured   \n",
       "\n",
       "      Correct_Answer  is_correct NewCategory  \n",
       "0  \\( \\frac{1}{3} \\)           1     Correct  \n",
       "1  \\( \\frac{1}{3} \\)           1     Correct  \n",
       "2  \\( \\frac{1}{3} \\)           1     Neither  \n",
       "3  \\( \\frac{1}{3} \\)           1     Neither  \n",
       "4  \\( \\frac{1}{3} \\)           1     Correct  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collapse Category into NewCategory\n",
    "train['NewCategory'] = train[\"Category\"].str.split(\"_\").str[1]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1683f89",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "Because I'm trying to predict 2 target variables (`Category` and `Misconception`), I'm going to take a hierarchical approach. First I'll attempt to predict `Category`, then if there is a misconception, I'll go on to predict `Misconception`. For the baseline, I'm going to start with a Multinomial Naive Bayes model & TfidfVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3caccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      False_Correct       0.00      0.00      0.00        39\n",
      "False_Misconception       0.70      0.71      0.71      1984\n",
      "      False_Neither       0.76      0.33      0.46      1238\n",
      "       True_Correct       0.64      0.99      0.78      2969\n",
      " True_Misconception       0.00      0.00      0.00        79\n",
      "       True_Neither       0.81      0.15      0.25      1031\n",
      "\n",
      "           accuracy                           0.67      7340\n",
      "          macro avg       0.49      0.36      0.37      7340\n",
      "       weighted avg       0.69      0.67      0.62      7340\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Try it with the original Category first\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train[[\"QuestionId\", \"PreprocessedExplanation\",'is_correct']], train[\"Category\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocess explanation, fit only on training data\n",
    "def tok(text):\n",
    "    tt = ToktokTokenizer()\n",
    "    return tt.tokenize(text)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,1), max_features=10000,tokenizer=tok)\n",
    "X_train_text = tfidf.fit_transform(X_train[\"PreprocessedExplanation\"])\n",
    "X_test_text  = tfidf.transform(X_test[\"PreprocessedExplanation\"])\n",
    "\n",
    "# Combine features\n",
    "X_train_final = hstack([X_train_text, X_train[['QuestionId','is_correct']]])\n",
    "X_test_final = hstack([X_test_text, X_test[['QuestionId','is_correct']]])\n",
    "\n",
    "# Train MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_final, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = nb.predict(X_test_final)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d95763ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Correct       0.68      0.90      0.78      3008\n",
      "Misconception       0.72      0.64      0.68      2063\n",
      "      Neither       0.61      0.40      0.49      2269\n",
      "\n",
      "     accuracy                           0.68      7340\n",
      "    macro avg       0.67      0.65      0.65      7340\n",
      " weighted avg       0.67      0.68      0.66      7340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Then try with NewCategory\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train[[\"QuestionId\", \"PreprocessedExplanation\",'is_correct']], train[\"NewCategory\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocess explanation, fit only on training data\n",
    "def tok(text):\n",
    "    tt = ToktokTokenizer()\n",
    "    return tt.tokenize(text)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,1), max_features=10000,tokenizer=tok)\n",
    "X_train_text = tfidf.fit_transform(X_train[\"PreprocessedExplanation\"])\n",
    "X_test_text  = tfidf.transform(X_test[\"PreprocessedExplanation\"])\n",
    "\n",
    "# Combine features\n",
    "X_train_final = hstack([X_train_text, X_train[['QuestionId','is_correct']]])\n",
    "X_test_final = hstack([X_test_text, X_test[['QuestionId','is_correct']]])\n",
    "\n",
    "# Train MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_final, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = nb.predict(X_test_final)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d5c48",
   "metadata": {},
   "source": [
    "Tune alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28910f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 0.1}\n",
      "Best CV score: 0.6405889498290076\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Correct       0.69      0.89      0.78      3008\n",
      "Misconception       0.71      0.66      0.68      2063\n",
      "      Neither       0.59      0.41      0.48      2269\n",
      "\n",
      "     accuracy                           0.67      7340\n",
      "    macro avg       0.66      0.65      0.65      7340\n",
      " weighted avg       0.67      0.67      0.66      7340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"alpha\": [0.01, 0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "grid = GridSearchCV(MultinomialNB(), param_grid, scoring=\"f1_macro\", cv=5, n_jobs=-1)\n",
    "grid.fit(X_train_final, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "\n",
    "y_pred = grid.best_estimator_.predict(X_test_final)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8859fcd",
   "metadata": {},
   "source": [
    "Tune TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13d832f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Correct       0.76      0.82      0.79      3765\n",
      "Misconception       0.73      0.78      0.76      2549\n",
      "      Neither       0.60      0.50      0.55      2860\n",
      "\n",
      "     accuracy                           0.71      9174\n",
      "    macro avg       0.70      0.70      0.70      9174\n",
      " weighted avg       0.70      0.71      0.70      9174\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train[[\"QuestionId\", \"PreprocessedExplanation\",'is_correct']], train[\"NewCategory\"], test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocess explanation, fit only on training data\n",
    "def tok(text):\n",
    "    tt = ToktokTokenizer()\n",
    "    return tt.tokenize(text)\n",
    "\n",
    "# Tune ngram_range (1,1) (1,2) or (1,3), max_features 10000 20000 or 50000, and set sublinear_tf = True\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=50000,sublinear_tf=True,tokenizer=tok)\n",
    "X_train_text = tfidf.fit_transform(X_train[\"PreprocessedExplanation\"])\n",
    "X_test_text  = tfidf.transform(X_test[\"PreprocessedExplanation\"])\n",
    "\n",
    "# Combine features\n",
    "X_train_final = hstack([X_train_text, X_train[['QuestionId','is_correct']]])\n",
    "X_test_final = hstack([X_test_text, X_test[['QuestionId','is_correct']]])\n",
    "\n",
    "# Handle class imbalance\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X_train_final, y_train)\n",
    "\n",
    "# Train MultinomialNB\n",
    "nb_stage1 = MultinomialNB(alpha=0.5)\n",
    "nb_stage1.fit(X_res, y_res)\n",
    "\n",
    "# predict\n",
    "y_pred = nb_stage1.predict(X_test_final)\n",
    "print('Stage 1 Report:\\n',classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03a96260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have a column in your train DataFrame: 'MisconceptionType'\n",
    "# This is the fine-grained label\n",
    "\n",
    "# Align features after resampling with the MisconceptionType column\n",
    "# First, get the mask for rows that are Misconception in the resampled data\n",
    "mask_stage2_train = (y_res == \"Misconception\")\n",
    "\n",
    "# Features for Stage 2\n",
    "X_train_stage2 = X_res[mask_stage2_train]\n",
    "\n",
    "# Target for Stage 2 (aligned with X_train_stage2)\n",
    "# To align, we need to get the corresponding rows from the original train DataFrame\n",
    "# Use the indices returned by RandomOverSampler\n",
    "miscon_indices = ros.sample_indices_[mask_stage2_train]  # indices of Misconception rows in the original X_train_final\n",
    "y_train_stage2 = train.iloc[miscon_indices][\"MisconceptionType\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb5ff7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB(alpha=0.1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_stage2 = MultinomialNB(alpha=0.1)\n",
    "nb_stage2.fit(X_train_stage2, y_train_stage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce8a52bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cq/gp4mmh_532d1t3573lxjzj5w0000gp/T/ipykernel_31826/274465657.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  results[\"misconception_type_pred\"].fillna(\"N/A\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 predictions\n",
    "y_pred_stage1 = nb_stage1.predict(X_test_final)\n",
    "\n",
    "# Mask rows predicted as Misconception\n",
    "mask_stage2_test = (y_pred_stage1 == \"Misconception\")\n",
    "\n",
    "# Convert to CSR for slicing\n",
    "X_test_final = X_test_final.tocsr()\n",
    "\n",
    "# Stage 2 features\n",
    "X_test_stage2 = X_test_final[mask_stage2_test]\n",
    "\n",
    "# Stage 2 predictions\n",
    "y_pred_stage2 = nb_stage2.predict(X_test_stage2)\n",
    "\n",
    "# Combine results\n",
    "results = pd.DataFrame({\"category_pred\": y_pred_stage1}, index=X_test.index)\n",
    "results.loc[mask_stage2_test, \"misconception_type_pred\"] = y_pred_stage2\n",
    "results[\"misconception_type_pred\"].fillna(\"N/A\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07ffafc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Correct       0.76      0.82      0.79      3765\n",
      "Misconception       0.73      0.78      0.76      2549\n",
      "      Neither       0.60      0.50      0.55      2860\n",
      "\n",
      "     accuracy                           0.71      9174\n",
      "    macro avg       0.70      0.70      0.70      9174\n",
      " weighted avg       0.70      0.71      0.70      9174\n",
      "\n",
      "Stage 2 report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           N/A       0.00      0.00      0.00         0\n",
      "      addition       0.00      0.00      0.00       337\n",
      "    definition       0.00      0.00      0.00       161\n",
      "      fraction       0.00      0.00      0.00       322\n",
      "    incomplete       0.25      0.00      0.01       384\n",
      "multiplication       0.00      0.00      0.00       121\n",
      "          none       0.00      0.00      0.00         0\n",
      "     operation       0.00      0.00      0.00       114\n",
      "      positive       0.00      0.00      0.00       149\n",
      "     procedure       0.00      0.00      0.00       357\n",
      "   subtraction       0.00      0.00      0.00       153\n",
      "      variable       0.00      0.00      0.00       290\n",
      "   wholenumber       1.00      0.01      0.02       161\n",
      "\n",
      "      accuracy                           0.00      2549\n",
      "     macro avg       0.10      0.00      0.00      2549\n",
      "  weighted avg       0.10      0.00      0.00      2549\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Stage 1 evaluation\n",
    "print(\"Stage 1 report:\\n\", classification_report(y_test, results[\"category_pred\"]))\n",
    "\n",
    "# Stage 2 evaluation (only on true Misconception rows in test set)\n",
    "mask_true_mis = (y_test == \"Misconception\")\n",
    "true_types = train.loc[X_test.index[mask_true_mis], \"MisconceptionType\"]\n",
    "pred_types = results.loc[mask_true_mis, \"misconception_type_pred\"]\n",
    "print(\"Stage 2 report:\\n\", classification_report(true_types, pred_types))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66171cc3",
   "metadata": {},
   "source": [
    "### 2 step classification notes\n",
    "When we only take the predicted Misconception category from the test set, it's too small to give a nice prediction of MisconceptionType. Compare to below where I just predict MisconceptionType from the full data set. Maybe I should just combine NewCategory and MisconceptionType into one target variable, then predict that with Naive Bayes or a tree method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaafd2d",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Summary (Baseline Model)\n",
    "- Overall, not a bad baseline model \n",
    "- Collapsed NewCategory works better than Category because it's so hard to categorize the rare cases (e.g., False_Correct & True_Misconception)\n",
    "- Perhaps unsurprisingly, the '_Neither' categories are the most difficult to categorize, though this improves slightly with tuning\n",
    "\n",
    "Now let's train the Misconception types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d1c92c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      addition       0.85      0.81      0.83       269\n",
      "    definition       0.92      0.96      0.94       114\n",
      "      fraction       0.65      0.77      0.71       237\n",
      "    incomplete       0.85      0.95      0.89       301\n",
      "multiplication       0.91      0.51      0.65        94\n",
      "     operation       0.84      0.34      0.49       108\n",
      "      positive       0.95      0.92      0.93       119\n",
      "     procedure       0.71      0.82      0.76       268\n",
      "   subtraction       0.94      0.84      0.89       122\n",
      "      variable       0.74      0.94      0.83       217\n",
      "   wholenumber       0.96      0.57      0.71       123\n",
      "\n",
      "      accuracy                           0.80      1972\n",
      "     macro avg       0.85      0.77      0.78      1972\n",
      "  weighted avg       0.82      0.80      0.80      1972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try with y = Misconception only for values with a misconception\n",
    "train_subset = train[train['NewCategory']=='Misconception']\n",
    "   \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_subset[[\"QuestionId\", \"PreprocessedExplanation\",'is_correct']], train_subset[\"MisconceptionType\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocess explanation, fit only on training data\n",
    "def tok(text):\n",
    "    tt = ToktokTokenizer()\n",
    "    return tt.tokenize(text)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=50000,tokenizer=tok,sublinear_tf=True)\n",
    "X_train_text = tfidf.fit_transform(X_train[\"PreprocessedExplanation\"])\n",
    "X_test_text  = tfidf.transform(X_test[\"PreprocessedExplanation\"])\n",
    "\n",
    "# Combine features\n",
    "X_train_final = hstack([X_train_text, X_train[['QuestionId','is_correct']]])\n",
    "X_test_final = hstack([X_test_text, X_test[['QuestionId','is_correct']]])\n",
    "\n",
    "# Train MultinomialNB\n",
    "nb = MultinomialNB(alpha=0.1)\n",
    "nb.fit(X_train_final, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = nb.predict(X_test_final)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1f15f",
   "metadata": {},
   "source": [
    "### Ask Aditya\n",
    "How would I set this up to 1st predict if there is a misconception, then predict what kind only for those the model predicted to be a misconception?\n",
    "\n",
    "What model would you try after this? A neural network (CNN?), a transformer (BERT,GPT)? \n",
    "\n",
    "Data set size: ~37K rows\n",
    "\n",
    "But <10K records with a misconception\n",
    "\n",
    "\n",
    "Remake X with y_pred then put thru next model \n",
    "My accuracy score is pretty good, but BERT could advance it. Might not need all the features, just the PreprocessedExplanation. Can try it, but keep it simple. If you see a score around 68 or 70, it's promising\n",
    "\n",
    "For many categories, may need to try RandomForest or XGBoost or GradientBoost or CatBoost \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c0ab2e",
   "metadata": {},
   "source": [
    "### Combining NewCategory and MisconceptionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26c77608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewCategory</th>\n",
       "      <th>MisconceptionType</th>\n",
       "      <th>CombinedTarget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36686</th>\n",
       "      <td>Neither</td>\n",
       "      <td>none</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36687</th>\n",
       "      <td>Neither</td>\n",
       "      <td>none</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36688</th>\n",
       "      <td>Misconception</td>\n",
       "      <td>definition</td>\n",
       "      <td>definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36689</th>\n",
       "      <td>Misconception</td>\n",
       "      <td>definition</td>\n",
       "      <td>definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36690</th>\n",
       "      <td>Neither</td>\n",
       "      <td>none</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36691</th>\n",
       "      <td>Neither</td>\n",
       "      <td>none</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36692</th>\n",
       "      <td>Neither</td>\n",
       "      <td>none</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36693</th>\n",
       "      <td>Neither</td>\n",
       "      <td>none</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36694</th>\n",
       "      <td>Neither</td>\n",
       "      <td>none</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36695</th>\n",
       "      <td>Neither</td>\n",
       "      <td>none</td>\n",
       "      <td>Neither</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NewCategory MisconceptionType CombinedTarget\n",
       "36686        Neither              none        Neither\n",
       "36687        Neither              none        Neither\n",
       "36688  Misconception        definition     definition\n",
       "36689  Misconception        definition     definition\n",
       "36690        Neither              none        Neither\n",
       "36691        Neither              none        Neither\n",
       "36692        Neither              none        Neither\n",
       "36693        Neither              none        Neither\n",
       "36694        Neither              none        Neither\n",
       "36695        Neither              none        Neither"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy to avoid modifying the original\n",
    "train_combined = train.copy()\n",
    "\n",
    "# Replace 'Misconception' in NewCategory with the MisconceptionType\n",
    "train_combined[\"CombinedTarget\"] = train_combined.apply(\n",
    "    lambda row: row[\"MisconceptionType\"] if row[\"NewCategory\"] == \"Misconception\" \n",
    "                else row[\"NewCategory\"],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Check results\n",
    "train_combined[[\"NewCategory\", \"MisconceptionType\", \"CombinedTarget\"]].tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebf6d5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Target Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Correct       0.79      0.70      0.74      3765\n",
      "       Neither       0.65      0.37      0.48      2860\n",
      "      addition       0.65      0.69      0.66       337\n",
      "    definition       0.43      0.90      0.58       161\n",
      "      fraction       0.46      0.54      0.50       322\n",
      "    incomplete       0.61      0.86      0.71       384\n",
      "multiplication       0.32      0.75      0.45       121\n",
      "     operation       0.38      0.54      0.44       114\n",
      "      positive       0.43      0.93      0.59       149\n",
      "     procedure       0.49      0.66      0.56       357\n",
      "   subtraction       0.55      0.86      0.68       153\n",
      "      variable       0.30      0.80      0.43       290\n",
      "   wholenumber       0.39      0.74      0.51       161\n",
      "\n",
      "      accuracy                           0.61      9174\n",
      "     macro avg       0.50      0.72      0.56      9174\n",
      "  weighted avg       0.66      0.61      0.61      9174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_combined[[\"QuestionId\", \"PreprocessedExplanation\",'is_correct']], train_combined[\"CombinedTarget\"], test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Preprocess explanation, fit only on training data\n",
    "def tok(text):\n",
    "    tt = ToktokTokenizer()\n",
    "    return tt.tokenize(text)\n",
    "\n",
    "# Tune ngram_range (1,1) (1,2) or (1,3), max_features 10000 20000 or 50000, and set sublinear_tf = True\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,3), max_features=50000,sublinear_tf=True,tokenizer=tok)\n",
    "X_train_text = tfidf.fit_transform(X_train[\"PreprocessedExplanation\"])\n",
    "X_test_text  = tfidf.transform(X_test[\"PreprocessedExplanation\"])\n",
    "\n",
    "# Combine features\n",
    "X_train_final = hstack([X_train_text, X_train[['QuestionId','is_correct']]])\n",
    "X_test_final = hstack([X_test_text, X_test[['QuestionId','is_correct']]])\n",
    "\n",
    "# Handle class imbalance\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X_train_final, y_train)\n",
    "\n",
    "# Train MultinomialNB\n",
    "nb = MultinomialNB(alpha=0.1)\n",
    "nb.fit(X_res, y_res)\n",
    "\n",
    "# predict\n",
    "y_pred = nb.predict(X_test_final)\n",
    "print('Combined Target Report:\\n',classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e134119a",
   "metadata": {},
   "source": [
    "### Combined Target with Naive Bayes\n",
    "It looks like the combined target is worth pursuing. I'm getting better results than I did with the transformer models and neural networks, which all ended up with an F1 score around 0.41. I may be able to get even better results with a a tree model that's better suited to many classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff75908",
   "metadata": {},
   "source": [
    "### Random Forest Model on the Combined Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcabe013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:484: FutureWarning: `BaseEstimator._check_n_features` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_n_features` instead.\n",
      "  warnings.warn(\n",
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:493: FutureWarning: `BaseEstimator._check_feature_names` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation._check_feature_names` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.085070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 85339\n",
      "[LightGBM] [Info] Number of data points in the train set: 146536, number of used features: 11161\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n",
      "[LightGBM] [Info] Start training from score -2.564949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgia/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Target Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Correct       0.83      0.87      0.85      3757\n",
      "       Neither       0.68      0.57      0.62      2952\n",
      "      addition       0.77      0.90      0.83       333\n",
      "    definition       0.77      0.75      0.76       152\n",
      "      fraction       0.62      0.79      0.70       310\n",
      "    incomplete       0.74      0.78      0.76       364\n",
      "multiplication       0.68      0.76      0.72       112\n",
      "     operation       0.62      0.66      0.64       126\n",
      "      positive       0.75      0.77      0.76       142\n",
      "     procedure       0.72      0.80      0.75       325\n",
      "   subtraction       0.71      0.83      0.76       155\n",
      "      variable       0.69      0.80      0.74       277\n",
      "   wholenumber       0.66      0.76      0.71       169\n",
      "\n",
      "      accuracy                           0.75      9174\n",
      "     macro avg       0.71      0.77      0.74      9174\n",
      "  weighted avg       0.75      0.75      0.75      9174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Train/test split\n",
    "# -----------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_combined[[\"QuestionId\", \"PreprocessedExplanation\", \"is_correct\"]],\n",
    "    train_combined[\"CombinedTarget\"],\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=train_combined[\"CombinedTarget\"]\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Text preprocessing (TF-IDF)\n",
    "# -----------------------\n",
    "def tok(text):\n",
    "    tt = ToktokTokenizer()\n",
    "    return tt.tokenize(text)\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=50000,\n",
    "    sublinear_tf=True,\n",
    "    tokenizer=tok\n",
    ")\n",
    "\n",
    "X_train_text = tfidf.fit_transform(X_train[\"PreprocessedExplanation\"])\n",
    "X_test_text  = tfidf.transform(X_test[\"PreprocessedExplanation\"])\n",
    "\n",
    "# -----------------------\n",
    "# Encode categorical QuestionId\n",
    "# -----------------------\n",
    "le_qid = LabelEncoder()\n",
    "X_train_qid = le_qid.fit_transform(X_train[\"QuestionId\"])\n",
    "X_test_qid  = le_qid.transform(X_test[\"QuestionId\"])\n",
    "\n",
    "# Convert to sparse column\n",
    "X_train_qid = csr_matrix(X_train_qid.reshape(-1, 1))\n",
    "X_test_qid  = csr_matrix(X_test_qid.reshape(-1, 1))\n",
    "\n",
    "# Binary feature is_correct\n",
    "X_train_ic = csr_matrix(X_train[[\"is_correct\"]].values)\n",
    "X_test_ic  = csr_matrix(X_test[[\"is_correct\"]].values)\n",
    "\n",
    "# -----------------------\n",
    "# Combine features\n",
    "# -----------------------\n",
    "X_train_final = hstack([X_train_text, X_train_qid, X_train_ic])\n",
    "X_test_final  = hstack([X_test_text, X_test_qid, X_test_ic])\n",
    "\n",
    "# -----------------------\n",
    "# Handle class imbalance\n",
    "# -----------------------\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X_train_final, y_train)\n",
    "\n",
    "# -----------------------\n",
    "# Train LightGBM classifier\n",
    "# -----------------------\n",
    "lgbm = lgb.LGBMClassifier(\n",
    "    boosting_type=\"gbdt\",\n",
    "    objective=\"multiclass\",\n",
    "    num_class=len(np.unique(y_res)),\n",
    "    class_weight=\"balanced\",\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm.fit(X_res, y_res)\n",
    "\n",
    "# -----------------------\n",
    "# Evaluate\n",
    "# -----------------------\n",
    "y_pred = lgbm.predict(X_test_final)\n",
    "print(\"Combined Target Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a547b28",
   "metadata": {},
   "source": [
    "I ran an Optuna (code block is commented below because it took 5 hours to run) and got these as best hyperparameters for the LightGBM. However, even with these paramenters, the F1 score remained 0.75. Precision went down, recall went up, and the model takes longer to run using these, so I'm going to stick with the LightGBM model above. \n",
    "\n",
    "Best Params: {'learning_rate': 0.17023808662117607, 'num_leaves': 132, 'max_depth': 18, 'min_child_samples': 15, 'subsample': 0.6953521929320011, 'colsample_bytree': 0.6003865687794745, 'reg_alpha': 0.11758490315889479, 'reg_lambda': 1.01328368773827}\n",
    "Best CV F1: 0.9505423352733698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b5a064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DON'T RUN UNLESS YOU HAVE 5 HOURS \n",
    "\n",
    "# # -----------------------\n",
    "# # Train/test split\n",
    "# # -----------------------\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     train_combined[[\"QuestionId\", \"PreprocessedExplanation\", \"is_correct\"]],\n",
    "#     train_combined[\"CombinedTarget\"],\n",
    "#     test_size=0.25,\n",
    "#     random_state=42,\n",
    "#     stratify=train_combined[\"CombinedTarget\"]\n",
    "# )\n",
    "\n",
    "# # -----------------------\n",
    "# # Text preprocessing (TF-IDF)\n",
    "# # -----------------------\n",
    "# def tok(text):\n",
    "#     tt = ToktokTokenizer()\n",
    "#     return tt.tokenize(text)\n",
    "\n",
    "# tfidf = TfidfVectorizer(\n",
    "#     ngram_range=(1, 3),\n",
    "#     max_features=50000,\n",
    "#     sublinear_tf=True,\n",
    "#     tokenizer=tok\n",
    "# )\n",
    "\n",
    "# X_train_text = tfidf.fit_transform(X_train[\"PreprocessedExplanation\"])\n",
    "# X_test_text  = tfidf.transform(X_test[\"PreprocessedExplanation\"])\n",
    "\n",
    "# # -----------------------\n",
    "# # Encode categorical QuestionId\n",
    "# # -----------------------\n",
    "# le_qid = LabelEncoder()\n",
    "# X_train_qid = le_qid.fit_transform(X_train[\"QuestionId\"])\n",
    "# X_test_qid  = le_qid.transform(X_test[\"QuestionId\"])\n",
    "\n",
    "# X_train_qid = csr_matrix(X_train_qid.reshape(-1, 1))\n",
    "# X_test_qid  = csr_matrix(X_test_qid.reshape(-1, 1))\n",
    "\n",
    "# # -----------------------\n",
    "# # Binary feature is_correct\n",
    "# # -----------------------\n",
    "# X_train_ic = csr_matrix(X_train[[\"is_correct\"]].values)\n",
    "# X_test_ic  = csr_matrix(X_test[[\"is_correct\"]].values)\n",
    "\n",
    "# # -----------------------\n",
    "# # Combine features\n",
    "# # -----------------------\n",
    "# X_train_final = hstack([X_train_text, X_train_qid, X_train_ic])\n",
    "# X_test_final  = hstack([X_test_text, X_test_qid, X_test_ic])\n",
    "\n",
    "# # -----------------------\n",
    "# # Handle class imbalance\n",
    "# # -----------------------\n",
    "# ros = RandomOverSampler(random_state=42)\n",
    "# X_res, y_res = ros.fit_resample(X_train_final, y_train)\n",
    "\n",
    "# # Encode y for LightGBM\n",
    "# le_y = LabelEncoder()\n",
    "# y_res_enc = le_y.fit_transform(y_res)\n",
    "# y_test_enc = le_y.transform(y_test)\n",
    "\n",
    "# # -----------------------\n",
    "# # Optuna Objective\n",
    "# # -----------------------\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         \"n_estimators\": 500,\n",
    "#         \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "#         \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "#         \"max_depth\": trial.suggest_int(\"max_depth\", -1, 20),\n",
    "#         \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "#         \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "#         \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "#         \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
    "#         \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
    "#         \"objective\": \"multiclass\",\n",
    "#         \"num_class\": len(np.unique(y_res_enc)),\n",
    "#         \"random_state\": 42,\n",
    "#         \"n_jobs\": -1\n",
    "#     }\n",
    "\n",
    "#     cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "#     f1_scores = []\n",
    "\n",
    "#     for train_idx, valid_idx in cv.split(X_res, y_res_enc):\n",
    "#         X_tr, X_val = X_res[train_idx], X_res[valid_idx]\n",
    "#         y_tr, y_val = y_res_enc[train_idx], y_res_enc[valid_idx]\n",
    "\n",
    "#         model = LGBMClassifier(**params)\n",
    "#         model.fit(X_tr, y_tr)\n",
    "\n",
    "#         preds = model.predict(X_val)\n",
    "#         f1_scores.append(f1_score(y_val, preds, average=\"macro\"))\n",
    "\n",
    "#     return np.mean(f1_scores)\n",
    "\n",
    "# # -----------------------\n",
    "# # Run Optuna\n",
    "# # -----------------------\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=30)\n",
    "\n",
    "# print(\"Best Params:\", study.best_params)\n",
    "# print(\"Best CV F1:\", study.best_value)\n",
    "\n",
    "# # -----------------------\n",
    "# # Train final model with best params\n",
    "# # -----------------------\n",
    "# best_model = LGBMClassifier(**study.best_params)\n",
    "# best_model.fit(X_res, y_res_enc)\n",
    "\n",
    "# # -----------------------\n",
    "# # Evaluate on test set\n",
    "# # -----------------------\n",
    "# y_pred = best_model.predict(X_test_final)\n",
    "# print(\"Combined Target Report:\\n\", classification_report(y_test_enc, y_pred, target_names=le_y.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
